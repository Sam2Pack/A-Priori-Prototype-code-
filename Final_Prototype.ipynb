{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "FBL6iY_VcmrY"
      },
      "outputs": [],
      "source": [
        "#importing the libraries\n",
        "import time\n",
        "import matplotlib.pyplot as plt\n",
        "from google import genai\n",
        "import pandas as pd\n",
        "import requests\n",
        "from tqdm import tqdm\n",
        "from google.colab import userdata"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the dataframe\n",
        "df=pd.read_csv('NPI_Extract_corr.csv')\n",
        "# Clean column names\n",
        "df.columns = [c.strip().lower().replace(\" \", \"_\") for c in df.columns]\n",
        "print(\"CSV loaded. Shape:\", df.shape)\n",
        "print(\"Columns:\", df.columns.tolist())\n",
        "print(\"\\nFirst few rows:\")\n",
        "print(df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f6ZxrE3se74F",
        "outputId": "001b7f12-bedc-4639-f4ae-00d8f69746d7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CSV loaded. Shape: (1000, 6)\n",
            "Columns: ['npi', 'provider_organization_name_(legal_business_name)', 'provider_last_name_(legal_name)', 'provider_first_name', 'provider_middle_name', 'provider_first_line_business_practice_location_address']\n",
            "\n",
            "First few rows:\n",
            "          npi provider_organization_name_(legal_business_name)  \\\n",
            "0  1679576722                                              NaN   \n",
            "1  1588667638                                              NaN   \n",
            "2  1497758544           CUMBERLAND COUNTY HOSPITAL SYSTEM, INC   \n",
            "3  1306849450                                              NaN   \n",
            "4  1215930367                                              NaN   \n",
            "\n",
            "  provider_last_name_(legal_name) provider_first_name provider_middle_name  \\\n",
            "0                           WIEBE               DAVID                    A   \n",
            "1                         PILCHER             WILLIAM                    C   \n",
            "2                             NaN                 NaN                  NaN   \n",
            "3                             NaN                 NaN                  NaN   \n",
            "4                         GRESSOT             LAURENT                  NaN   \n",
            "\n",
            "  provider_first_line_business_practice_location_address  \n",
            "0                                   3500 CENTRAL AVE      \n",
            "1                                   1824 KING STREET      \n",
            "2                                    3418 VILLAGE DR      \n",
            "3                                                NaN      \n",
            "4                                   17323 RED OAK DR      \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the gemini api key\n",
        "k=userdata.get('API_key')\n",
        "client = genai.Client(api_key=k)"
      ],
      "metadata": {
        "id": "h2M92rq3qYlp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the data validation agent and the npi validation agent\n",
        "import requests\n",
        "def data_validation_agent(row):\n",
        "    \"\"\"Basic format/structure validation\"\"\"\n",
        "    npi = str(row.get(\"npi\", \"\")).strip()\n",
        "    addr = str(row.get(\"provider_first_line_business_practice_location_address\", \"\")).strip()\n",
        "\n",
        "    return {\n",
        "        \"npi_format_valid\": len(npi) == 10 and npi.isdigit(),\n",
        "        \"address_present\": len(addr) > 5,\n",
        "        \"raw_data_quality\": \"GOOD\" if len(npi) > 0 and len(addr) > 0 else \"POOR\"}\n",
        "def npi_validation_agent(row):\n",
        "    npi = str(row.get(\"npi\", \"\")).strip()\n",
        "    # Basic NPI format check\n",
        "    if len(npi) != 10 or not npi.isdigit():\n",
        "        return {\n",
        "            \"npi_valid\": False,\n",
        "            \"npi_status\": \"INVALID_FORMAT\",\n",
        "            \"npi_name\": \"\",\n",
        "            \"npi_address\": \"\",\n",
        "            \"npi_taxonomy_code\": \"\",\n",
        "            \"npi_taxonomy_desc\": \"\",\n",
        "            \"name_match\": False,\n",
        "            \"address_match\": False,\n",
        "        }\n",
        "\n",
        "    url = f\"https://npiregistry.cms.hhs.gov/api/?number={npi}&version=2.1\"\n",
        "    try:\n",
        "        resp = requests.get(url, timeout=10)\n",
        "        data = resp.json()\n",
        "\n",
        "        if data.get(\"result_count\", 0) != 1:\n",
        "            return {\n",
        "                \"npi_valid\": False,\n",
        "                \"npi_status\": \"NOT_FOUND\",\n",
        "                \"npi_name\": \"\",\n",
        "                \"npi_address\": \"\",\n",
        "                \"npi_taxonomy_code\": \"\",\n",
        "                \"npi_taxonomy_desc\": \"\",\n",
        "                \"name_match\": False,\n",
        "                \"address_match\": False,\n",
        "            }\n",
        "        rec = data[\"results\"][0]\n",
        "        npi_basic = rec.get(\"basic\", {})\n",
        "        npi_addresses = rec.get(\"addresses\", [])\n",
        "        taxonomies = rec.get(\"taxonomies\", [])\n",
        "        npi_first = npi_basic.get(\"first_name\", \"\") or \"\"\n",
        "        npi_last  = npi_basic.get(\"last_name\", \"\") or \"\"\n",
        "        npi_org   = npi_basic.get(\"legal_business_name\", \"\") or \"\"\n",
        "        npi_full_indiv = f\"{npi_first} {npi_last}\".strip()\n",
        "        npi_name = npi_org if npi_org else npi_full_indiv\n",
        "        npi_address = npi_addresses[0].get(\"address_1\", \"\") if npi_addresses else \"\"\n",
        "\n",
        "        primary_tax = taxonomies[0] if taxonomies else {}\n",
        "        npi_taxonomy_code = primary_tax.get(\"code\", \"\")\n",
        "        npi_taxonomy_desc = primary_tax.get(\"desc\", \"\")\n",
        "        csv_first = str(row.get(\"provider_first_name\", \"\")).strip()\n",
        "        csv_last  = str(row.get(\"provider_last_name_(legal_name)\", \"\")).strip()\n",
        "        csv_org   = str(row.get(\"provider_organization_name_(legal_business_name)\", \"\")).strip()\n",
        "        csv_addr  = str(row.get(\"provider_first_line_business_practice_location_address\", \"\")).strip()\n",
        "        def norm_name(s):\n",
        "            return \" \".join(str(s).upper().split())\n",
        "\n",
        "        def norm_addr(s):\n",
        "            return \" \".join(str(s).upper().split())\n",
        "\n",
        "        csv_full_indiv = norm_name(f\"{csv_first} {csv_last}\")\n",
        "        npi_full_indiv = norm_name(npi_full_indiv)\n",
        "        csv_full_org   = norm_name(csv_org)\n",
        "        npi_full_org   = norm_name(npi_org)\n",
        "\n",
        "        indiv_name_match = (\n",
        "            csv_first != \"\" and csv_last != \"\" and\n",
        "            csv_full_indiv != \"\" and npi_full_indiv != \"\" and (\n",
        "                csv_full_indiv == npi_full_indiv or\n",
        "                csv_full_indiv in npi_full_indiv or\n",
        "                npi_full_indiv in csv_full_indiv\n",
        "            )\n",
        "        )\n",
        "\n",
        "        org_name_match = (\n",
        "            csv_full_org != \"\" and npi_full_org != \"\" and (\n",
        "                csv_full_org == npi_full_org or\n",
        "                csv_full_org in npi_full_org or\n",
        "                npi_full_org in csv_full_org\n",
        "            )\n",
        "        )\n",
        "        name_match = indiv_name_match or org_name_match\n",
        "        csv_addr_norm = norm_addr(csv_addr)\n",
        "        npi_addr_norm = norm_addr(npi_address)\n",
        "\n",
        "        address_match = (\n",
        "            csv_addr_norm != \"\" and npi_addr_norm != \"\" and (\n",
        "                csv_addr_norm == npi_addr_norm or\n",
        "                csv_addr_norm in npi_addr_norm or\n",
        "                npi_addr_norm in csv_addr_norm\n",
        "            )\n",
        "        )\n",
        "        return {\n",
        "    \"npi_valid\": True,\n",
        "    \"npi_status\": \"ACTIVE\",\n",
        "    \"npi_name\": npi_name,\n",
        "    \"npi_address\": npi_address,\n",
        "    \"npi_taxonomy_code\": npi_taxonomy_code,\n",
        "    \"npi_taxonomy_desc\": npi_taxonomy_desc,\n",
        "    \"name_match\": name_match,\n",
        "    \"address_match\": address_match,\n",
        "}\n",
        "\n",
        "    except Exception as e:\n",
        "        return {\n",
        "            \"npi_valid\": False,\n",
        "            \"npi_status\": f\"API_ERROR: {str(e)[:40]}\",\n",
        "        }\n"
      ],
      "metadata": {
        "id": "JOWac-0Jo-1U"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the quality assurance agent\n",
        "def quality_assurance_agent(row, validation_results, npi_results):\n",
        "    score = 0.0\n",
        "    # Structural checks\n",
        "    if validation_results.get(\"npi_format_valid\"):\n",
        "        score += 0.1\n",
        "    if validation_results.get(\"address_present\"):\n",
        "        score += 0.1\n",
        "    # NPI validity\n",
        "    if npi_results.get(\"npi_valid\"):\n",
        "        score += 0.4\n",
        "    # Name & address consistency\n",
        "    if npi_results.get(\"name_match\"):\n",
        "        score += 0.3\n",
        "    if npi_results.get(\"address_match\"):\n",
        "        score += 0.1\n",
        "    score = min(score, 1.0)\n",
        "    if score >= 0.8:\n",
        "        bucket = \"AUTO_ACCEPT\"\n",
        "    elif score >= 0.5:\n",
        "        bucket = \"REVIEW\"\n",
        "    else:\n",
        "        bucket = \"REJECT\"\n",
        "    return {\n",
        "        \"confidence_score\": round(score, 2),\n",
        "        \"qa_bucket\": bucket,\n",
        "        \"name_match\": bool(npi_results.get(\"name_match\", False)),\n",
        "        \"address_match\": bool(npi_results.get(\"address_match\", False)),\n",
        "    }\n",
        "\n"
      ],
      "metadata": {
        "id": "TV9D8O2hpR8K"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Public Data Source Enrichment agent\n",
        "def public_data_sources_enrichment_agent(row, npi_results):\n",
        "    #Gemini is being used to guess extra info\n",
        "    prompt = f\"\"\"\n",
        "    Given NPI data: {npi_results}\n",
        "    CSV data: {row.to_dict()}\n",
        "    \"\"\"\n",
        "    try:\n",
        "        resp = client.models.generate_content(model=\"gemini-1.5-flash\", contents=prompt)\n",
        "        import json, re\n",
        "        json_str = re.search(r'\\{.*\\}', resp.text, re.S)\n",
        "        if json_str:\n",
        "            return json.loads(json_str.group(0))\n",
        "    except:\n",
        "        pass\n",
        "    return {\"provider_type\": \"UNKNOWN\", \"likely_specialty\": \"UNKNOWN\", \"risk_flags\": []}\n"
      ],
      "metadata": {
        "id": "at-4hkaMpgzY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the information enrichment agent\n",
        "def information_enrichment_agent(row, enrichment_results, npi_results):\n",
        "    taxonomy_desc = npi_results.get(\"npi_taxonomy_desc\", \"\")\n",
        "    llm_specialty = enrichment_results.get(\"likely_specialty\", \"UNKNOWN\")\n",
        "    final_specialty = llm_specialty if llm_specialty != \"UNKNOWN\" else taxonomy_desc\n",
        "    return {\n",
        "        \"final_specialty\": final_specialty,\n",
        "        \"provider_type\": enrichment_results.get(\"provider_type\", \"UNKNOWN\"),\n",
        "        \"enriched_flags\": enrichment_results.get(\"risk_flags\", []),\n",
        "        \"npi_taxonomy_desc\": taxonomy_desc,\n",
        "        \"npi_taxonomy_code\": npi_results.get(\"npi_taxonomy_code\", \"\")\n",
        "    }"
      ],
      "metadata": {
        "id": "iL84jR6WrRV4"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#defining the directory management agent\n",
        "def directory_management_agent(df_processed):\n",
        "    auto = df_processed[df_processed[\"qa_bucket\"] == \"AUTO_ACCEPT\"]\n",
        "    review = df_processed[df_processed[\"qa_bucket\"] == \"REVIEW\"]\n",
        "    reject = df_processed[df_processed[\"qa_bucket\"] == \"REJECT\"]\n",
        "    print(f\"\\nDIRECTORY MANAGEMENT\")\n",
        "    print(f\"AUTO_ACCEPT: {len(auto)} | REVIEW: {len(review)} | REJECT: {len(reject)}\")\n",
        "    auto.to_csv(\"directory_auto_accept.csv\", index=False)\n",
        "    review.to_csv(\"directory_review.csv\", index=False)\n",
        "    reject.to_csv(\"directory_reject.csv\", index=False)\n",
        "    return auto, review, reject"
      ],
      "metadata": {
        "id": "UVFK-wPxtmSH"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#definng the master orchestrator agent\n",
        "def master_orchestrator_agent(df, limit=None):\n",
        "    if limit:\n",
        "        df_work = df.head(limit).copy()\n",
        "    else:\n",
        "        df_work = df.copy()\n",
        "    list_containing_columns = ['risk_flags', 'enriched_flags']\n",
        "    for col in list_containing_columns:\n",
        "        if col not in df_work.columns:\n",
        "            df_work[col] = pd.Series(index=df_work.index, dtype='object') # Initialize with NaN, but object dtype\n",
        "\n",
        "    for idx, row in tqdm(df_work.iterrows(), total=len(df_work), desc=\"Processing\"):\n",
        "        # Agent 1: Data Validation\n",
        "        v1 = data_validation_agent(row)\n",
        "        # Agent 2: NPI Validation (API)\n",
        "        v2 = npi_validation_agent(row)\n",
        "        # Agent 3: Quality Assurance\n",
        "        v3 = quality_assurance_agent(row, v1, v2)\n",
        "        # Agent 4: Public Data Enrichment (LLM)\n",
        "        v4 = public_data_sources_enrichment_agent(row, v2)\n",
        "        # Agent 5: Information Enrichment\n",
        "        v5 = information_enrichment_agent(row, v4,v2)\n",
        "\n",
        "        # Store ALL results\n",
        "        for agent_results in [v1, v2, v3, v4, v5]:\n",
        "            for k, v in agent_results.items():\n",
        "                df_work.at[idx, k] = v\n",
        "        time.sleep(0.2)\n",
        "\n",
        "    # Call directory_management_agent to get the auto, review, reject dataframes\n",
        "    auto, review, reject = directory_management_agent(df_work)\n",
        "\n",
        "    # Return df_work along with auto, review, reject to match the calling signature\n",
        "    return df_work, auto, review, reject\n"
      ],
      "metadata": {
        "id": "LrQBeQHAtu95"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Running the agent...\")\n",
        "df_final, auto, review, reject = master_orchestrator_agent(df, limit=None)\n",
        "print(\"\\n Pipeline complete! Check CSV outputs.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I91Za8mrumj4",
        "outputId": "8e890073-43f4-4064-e0a4-d1eb48c23ef3"
      },
      "execution_count": 10,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Running the agent...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 1000/1000 [05:08<00:00,  3.24it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DIRECTORY MANAGEMENT\n",
            "AUTO_ACCEPT: 679 | REVIEW: 239 | REJECT: 82\n",
            "\n",
            " Pipeline complete! Check CSV outputs.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "auto_existing   = pd.read_csv(\"directory_auto_accept.csv\")\n",
        "review_existing = pd.read_csv(\"directory_review.csv\")\n",
        "reject_existing = pd.read_csv(\"directory_reject.csv\")\n",
        "\n",
        "\n",
        "# This is the Sheet created by your Form (File → Share link)\n",
        "sheet_url = \"https://docs.google.com/spreadsheets/d/e/2PACX-1vQPUXTUYda3P2Y2IZzcWD7hMvtU9JyBkGt5uL0OKiR-Enr37dXFRvJMnOyjwegLvb0pv2Kud7VpSIIC/pub?gid=256121927&single=true&output=csv\"\n",
        "\n",
        "# Convert to CSV export URL\n",
        "csv_url = sheet_url.replace(\"/edit#gid=\", \"/export?format=csv&gid=\")\n",
        "\n",
        "df_raw = pd.read_csv(csv_url, on_bad_lines='skip')   # always gets latest responses\n",
        "\n",
        "\n",
        "df_new_valid, auto_new, review_new, reject_new = master_orchestrator_agent(df_raw)\n",
        "\n",
        "# Optional: tag source\n",
        "auto_new[\"source\"]   = \"new\"\n",
        "review_new[\"source\"] = \"new\"\n",
        "reject_new[\"source\"] = \"new\"\n",
        "\n",
        "# === 4) APPEND new results to existing CSVs ===\n",
        "auto_all   = pd.concat([auto_existing,   auto_new],   ignore_index=True)\n",
        "review_all = pd.concat([review_existing, review_new], ignore_index=True)\n",
        "reject_all = pd.concat([reject_existing, reject_new], ignore_index=True)\n",
        "\n",
        "auto_all.to_csv(\"directory_auto_accept.csv\", index=False)\n",
        "review_all.to_csv(\"directory_review.csv\", index=False)\n",
        "reject_all.to_csv(\"directory_reject.csv\", index=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Bk7tFt5rR6d5",
        "outputId": "f88a2bf6-41db-4028-a5ab-ae5c88e0464b"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Processing: 100%|██████████| 1/1 [00:00<00:00,  3.22it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "DIRECTORY MANAGEMENT\n",
            "AUTO_ACCEPT: 0 | REVIEW: 0 | REJECT: 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install streamlit\n",
        "!pip install ngrok"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pz5py34cl9OT",
        "outputId": "3aa3cc73-8221-40d1-d506-6f4fd9395fa3"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.52.1-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: altair!=5.4.0,!=5.4.1,<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.5.0)\n",
            "Requirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (1.9.0)\n",
            "Requirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.2.2)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (8.3.1)\n",
            "Requirement already satisfied: numpy<3,>=1.23 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.0.2)\n",
            "Requirement already satisfied: packaging>=20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (25.0)\n",
            "Requirement already satisfied: pandas<3,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.2.2)\n",
            "Requirement already satisfied: pillow<13,>=7.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (11.3.0)\n",
            "Requirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.12/dist-packages (from streamlit) (5.29.5)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (18.1.0)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.12/dist-packages (from streamlit) (2.32.4)\n",
            "Requirement already satisfied: tenacity<10,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (9.1.2)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.12/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.12/dist-packages (from streamlit) (4.15.0)\n",
            "Requirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.0.0)\n",
            "Requirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.12/dist-packages (from streamlit) (3.1.45)\n",
            "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
            "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.12/dist-packages (from streamlit) (6.5.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.1.6)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (4.25.1)\n",
            "Requirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.12/dist-packages (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2.13.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.12/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas<3,>=1.4.0->streamlit) (2025.2)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3,>=2.27->streamlit) (2025.11.12)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.12/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (3.0.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (25.4.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (2025.9.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.37.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.12/dist-packages (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit) (0.30.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
            "Downloading streamlit-1.52.1-py3-none-any.whl (9.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.0/9.0 MB\u001b[0m \u001b[31m61.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pydeck, streamlit\n",
            "Successfully installed pydeck-0.9.1 streamlit-1.52.1\n",
            "Collecting ngrok\n",
            "  Downloading ngrok-1.6.0-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Downloading ngrok-1.6.0-cp310-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m37.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: ngrok\n",
            "Successfully installed ngrok-1.6.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "import streamlit as st\n",
        "import pandas as pd\n",
        "\n",
        "st.set_page_config(page_title=\"Provider Validation Dashboard\", layout=\"wide\")\n",
        "st.caption(\"BUILD v9 – using directory_auto/review/reject.csv ONLY\")\n",
        "\n",
        "@st.cache_data\n",
        "def load_data():\n",
        "    df_auto   = pd.read_csv(\"directory_auto_accept.csv\")\n",
        "    df_reject = pd.read_csv(\"directory_reject.csv\")\n",
        "    df_review = pd.read_csv(\"directory_review.csv\")\n",
        "    return df_auto, df_reject, df_review\n",
        "\n",
        "df_auto, df_reject, df_review = load_data()\n",
        "total_providers = len(df_auto) + len(df_reject) + len(df_review)\n",
        "\n",
        "st.title(\"Provider Data Validation Dashboard\")\n",
        "\n",
        "col1, col2, col3, col4 = st.columns(4)\n",
        "col1.metric(\"Total providers\", total_providers)\n",
        "col2.metric(\"Auto-accept\", len(df_auto))\n",
        "col3.metric(\"Review\", len(df_review))\n",
        "col4.metric(\"Reject\", len(df_reject))\n",
        "\n",
        "st.markdown(\"---\")\n",
        "\n",
        "view = st.radio(\n",
        "    \"Select view\",\n",
        "    (\"AUTO_ACCEPT\", \"REJECT\", \"REVIEW\"),\n",
        "    horizontal=True\n",
        ")\n",
        "\n",
        "if view == \"AUTO_ACCEPT\":\n",
        "    view_df = df_auto.copy()\n",
        "elif view == \"REJECT\":\n",
        "    view_df = df_reject.copy()\n",
        "else:\n",
        "    view_df = df_review.copy()\n",
        "\n",
        "st.subheader(f\"{view} providers\")\n",
        "\n",
        "st.sidebar.header(\"Filters\")\n",
        "min_conf, max_conf = st.sidebar.slider(\n",
        "    \"Confidence score range\",\n",
        "    0.0, 1.0,\n",
        "    (0.0, 1.0),\n",
        "    0.05\n",
        ")\n",
        "\n",
        "if \"confidence_score\" in view_df.columns:\n",
        "    view_df = view_df[view_df[\"confidence_score\"].between(min_conf, max_conf)]\n",
        "\n",
        "cols_to_show = [c for c in [\n",
        "    \"npi\",\n",
        "    \"provider_organization_name_(legal_business_name)\",\n",
        "    \"provider_last_name_(legal_name)\",\n",
        "    \"provider_first_name\",\n",
        "    \"provider_first_line_business_practice_location_address\",\n",
        "    \"qa_bucket\",\n",
        "    \"confidence_score\",\n",
        "    \"npi_status\",\n",
        "    \"name_match\",\n",
        "    \"address_match\"\n",
        "] if c in view_df.columns]\n",
        "\n",
        "st.dataframe(view_df[cols_to_show].head(500), use_container_width=True)\n",
        "st.markdown(\"---\")\n",
        "c1, c2 = st.columns(2)\n",
        "\n",
        "with c1:\n",
        "    if \"confidence_score\" in view_df.columns and not view_df.empty:\n",
        "        st.markdown(f\"**Confidence score distribution – {view}**\")\n",
        "        st.bar_chart(view_df[\"confidence_score\"])\n",
        "\n",
        "with c2:\n",
        "    if \"npi_status\" in view_df.columns and not view_df.empty:\n",
        "        st.markdown(f\"**NPI status counts – {view}**\")\n",
        "        status_counts = view_df[\"npi_status\"].value_counts().reset_index()\n",
        "        status_counts.columns = [\"npi_status\", \"count\"]\n",
        "        st.bar_chart(status_counts.set_index(\"npi_status\"))\n"
      ],
      "metadata": {
        "id": "9DjF5yxQmt8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!sed -n '1,40p' app.py\n"
      ],
      "metadata": {
        "id": "H_C3gVi0mvcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kill -9 $(ps aux | grep 'streamlit run app.py' | awk '{print $2}') 2>/dev/null || echo \"no old streamlit\"\n",
        "!kill -9 $(ps aux | grep ngrok | awk '{print $2}') 2>/dev/null || echo \"no old ngrok\"\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XUNBoKeam8LF",
        "outputId": "10b531cd-b4fb-4cae-c3b9-0ae9bc40726d"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "^C\n",
            "^C\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pyngrok\n",
        "from pyngrok import ngrok\n",
        "from google.colab import userdata\n",
        "import time # Import time for sleep\n",
        "\n",
        "# Terminate any existing Streamlit and ngrok processes forcefully\n",
        "!kill -9 $(ps aux | grep 'streamlit run app.py' | awk '{print $2}') 2>/dev/null || echo \"no old streamlit\"\n",
        "!kill -9 $(ps aux | grep ngrok | awk '{print $2}') 2>/dev/null || echo \"no old ngrok\"\n",
        "\n",
        "# Add a small delay to ensure processes are fully terminated\n",
        "time.sleep(2)\n",
        "\n",
        "NGROK_AUTH_TOKEN = userdata.get('NGROK_AUTH_TOKEN')\n",
        "ngrok.set_auth_token(NGROK_AUTH_TOKEN)\n",
        "\n",
        "# Terminate any existing ngrok tunnels managed by pyngrok right before connecting\n",
        "ngrok.kill()\n",
        "\n",
        "public_url = ngrok.connect(8501)\n",
        "print(\"NEW URL:\", public_url)\n",
        "\n",
        "!streamlit run app.py --server.port 8501 --server.headless true &>/dev/null &"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L58Ir8GYm_9K",
        "outputId": "4598c89d-1f45-4c03-ce61-a1730a152789"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.12/dist-packages (7.5.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.12/dist-packages (from pyngrok) (6.0.3)\n",
            "^C\n",
            "^C\n",
            "NEW URL: NgrokTunnel: \"https://agronomical-asha-undared.ngrok-free.dev\" -> \"http://localhost:8501\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "raw = pd.read_csv(\"NPI_Extract_corr.csv\")  # or NPI_Extract.csv\n",
        "# Clean column names\n",
        "raw.columns = [c.strip().lower().replace(\" \", \"_\") for c in raw.columns]\n",
        "print(raw[[\"npi\",\n",
        "           \"provider_organization_name_(legal_business_name)\",\n",
        "           \"provider_last_name_(legal_name)\",\n",
        "           \"provider_first_name\"]].head(10))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnpXGXubHNLC",
        "outputId": "11f554cf-7a8b-4b33-cfb5-309706f93afa"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "          npi provider_organization_name_(legal_business_name)  \\\n",
            "0  1679576722                                              NaN   \n",
            "1  1588667638                                              NaN   \n",
            "2  1497758544           CUMBERLAND COUNTY HOSPITAL SYSTEM, INC   \n",
            "3  1306849450                                              NaN   \n",
            "4  1215930367                                              NaN   \n",
            "5  1023011178                                   COLLABRIA CARE   \n",
            "6  1932102084                                              NaN   \n",
            "7  1841293990                                              NaN   \n",
            "8  1750384806                                              NaN   \n",
            "9  1669475711                                              NaN   \n",
            "\n",
            "  provider_last_name_(legal_name) provider_first_name  \n",
            "0                           WIEBE               DAVID  \n",
            "1                         PILCHER             WILLIAM  \n",
            "2                             NaN                 NaN  \n",
            "3                             NaN                 NaN  \n",
            "4                         GRESSOT             LAURENT  \n",
            "5                             NaN                 NaN  \n",
            "6                      ADUSUMILLI                RAVI  \n",
            "7                        WORTSMAN               SUSAN  \n",
            "8                          BISBEE              ROBERT  \n",
            "9                            SUNG                 BIN  \n"
          ]
        }
      ]
    }
  ]
}